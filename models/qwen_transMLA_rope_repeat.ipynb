{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/transmla/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qwen2.modeling_qwen2 import Qwen2ForCausalLM\n",
    "from qwen2.configuration_qwen2 import Qwen2Config\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  2.77s/it]\n",
      "Some weights of Qwen2ForCausalLM were not initialized from the model checkpoint at /root/mfx/huggingface/Qwen/Qwen2.5-7B and are newly initialized: ['model.layers.0.self_attn.k_up_proj.weight', 'model.layers.0.self_attn.v_up_proj.weight', 'model.layers.1.self_attn.k_up_proj.weight', 'model.layers.1.self_attn.v_up_proj.weight', 'model.layers.10.self_attn.k_up_proj.weight', 'model.layers.10.self_attn.v_up_proj.weight', 'model.layers.11.self_attn.k_up_proj.weight', 'model.layers.11.self_attn.v_up_proj.weight', 'model.layers.12.self_attn.k_up_proj.weight', 'model.layers.12.self_attn.v_up_proj.weight', 'model.layers.13.self_attn.k_up_proj.weight', 'model.layers.13.self_attn.v_up_proj.weight', 'model.layers.14.self_attn.k_up_proj.weight', 'model.layers.14.self_attn.v_up_proj.weight', 'model.layers.15.self_attn.k_up_proj.weight', 'model.layers.15.self_attn.v_up_proj.weight', 'model.layers.16.self_attn.k_up_proj.weight', 'model.layers.16.self_attn.v_up_proj.weight', 'model.layers.17.self_attn.k_up_proj.weight', 'model.layers.17.self_attn.v_up_proj.weight', 'model.layers.18.self_attn.k_up_proj.weight', 'model.layers.18.self_attn.v_up_proj.weight', 'model.layers.19.self_attn.k_up_proj.weight', 'model.layers.19.self_attn.v_up_proj.weight', 'model.layers.2.self_attn.k_up_proj.weight', 'model.layers.2.self_attn.v_up_proj.weight', 'model.layers.20.self_attn.k_up_proj.weight', 'model.layers.20.self_attn.v_up_proj.weight', 'model.layers.21.self_attn.k_up_proj.weight', 'model.layers.21.self_attn.v_up_proj.weight', 'model.layers.22.self_attn.k_up_proj.weight', 'model.layers.22.self_attn.v_up_proj.weight', 'model.layers.23.self_attn.k_up_proj.weight', 'model.layers.23.self_attn.v_up_proj.weight', 'model.layers.24.self_attn.k_up_proj.weight', 'model.layers.24.self_attn.v_up_proj.weight', 'model.layers.25.self_attn.k_up_proj.weight', 'model.layers.25.self_attn.v_up_proj.weight', 'model.layers.26.self_attn.k_up_proj.weight', 'model.layers.26.self_attn.v_up_proj.weight', 'model.layers.27.self_attn.k_up_proj.weight', 'model.layers.27.self_attn.v_up_proj.weight', 'model.layers.3.self_attn.k_up_proj.weight', 'model.layers.3.self_attn.v_up_proj.weight', 'model.layers.4.self_attn.k_up_proj.weight', 'model.layers.4.self_attn.v_up_proj.weight', 'model.layers.5.self_attn.k_up_proj.weight', 'model.layers.5.self_attn.v_up_proj.weight', 'model.layers.6.self_attn.k_up_proj.weight', 'model.layers.6.self_attn.v_up_proj.weight', 'model.layers.7.self_attn.k_up_proj.weight', 'model.layers.7.self_attn.v_up_proj.weight', 'model.layers.8.self_attn.k_up_proj.weight', 'model.layers.8.self_attn.v_up_proj.weight', 'model.layers.9.self_attn.k_up_proj.weight', 'model.layers.9.self_attn.v_up_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2MLAttention(\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "          (k_up_proj): Linear(in_features=512, out_features=3584, bias=False)\n",
       "          (v_up_proj): Linear(in_features=512, out_features=3584, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Qwen2ForCausalLM.from_pretrained(\"/root/mfx/huggingface/Qwen/Qwen2.5-7B\", device_map='cuda:1', attn_implementation=\"eager\", partial_rotary_factor=1, rope_repeat=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/root/mfx/huggingface/Qwen/Qwen2.5-7B\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size = model.config.hidden_size\n",
    "n_heads = model.config.num_attention_heads\n",
    "kv_heads = model.config.num_key_value_heads\n",
    "head_dim = model.config.hidden_size//model.config.num_attention_heads\n",
    "latent_dim = kv_heads * head_dim\n",
    "kv_groups = model.config.num_attention_heads // model.config.num_key_value_heads\n",
    "model.config.partial_rotary_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert identity matrices\n",
    "for name,module in model.named_modules():\n",
    "    if 'k_up_proj' in name or \"v_up_proj\" in name:\n",
    "        module.weight.data = torch.stack([torch.eye(latent_dim).reshape(kv_heads, head_dim, latent_dim)]*kv_groups,dim=1).reshape(hidden_size, latent_dim).contiguous().to(module.weight.data.device,module.weight.data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给我讲一个故事吧。\n",
      "当然可以，这是一个关于勇气和友谊的故事：\n",
      "\n",
      "从前，在一个遥远的森林里，住着一只名叫蓝羽的小鸟。蓝羽有着美丽的蓝色羽毛和甜美的歌声，但它有一个秘密——它害怕飞翔。每当其他鸟儿在天空中自由翱翔时，蓝羽总是躲在树枝上，不敢加入它们。\n",
      "\n",
      "一天，森林里的动物们决定举办一场飞行比赛，以庆祝春天的到来。所有的鸟儿都兴奋地准备着，只有蓝羽感到非常焦虑。它知道如果不去参加比赛，它将永远无法克服自己的恐惧。\n",
      "\n",
      "就在这时，一只名叫风灵的老鹰飞到了蓝羽的树上。风灵是森林中最勇敢的鸟儿之一，它看到了蓝羽的不安。风灵对蓝羽说：“蓝羽，我知道你害怕飞翔，但请相信我，只要你勇敢地迈出第一步，你就能够学会飞翔。”\n",
      "\n",
      "受到风灵的鼓励，蓝羽鼓起勇气，决定参加飞行比赛。在比赛的那天，所有的动物都聚集在森林中央，期待着看到精彩的表演。蓝羽站在起跑线上，心跳加速，但它没有退缩。\n",
      "\n",
      "随着一声哨响，所有的鸟儿都展翅高飞，只有蓝羽还在原地。就在这时，风灵飞到了蓝羽的身边，用翅膀轻轻推了它一下。蓝羽感到一股力量涌上心头，它闭上眼睛，深吸一口气，然后张开翅膀，飞向了天空。\n",
      "\n",
      "起初，蓝羽的飞行并不平稳，但它没有放弃。它努力地扇动翅膀，逐渐掌握了飞行的技巧。其他鸟儿看到了蓝羽的努力，纷纷为它加油鼓劲。最终，蓝羽成功地完成了比赛，赢得了所有人的掌声和尊重。\n",
      "\n",
      "从那以后，蓝羽不再害怕飞翔。它成为了森林中最勇敢的鸟儿之一，它的故事也激励着其他动物去面对自己的恐惧，勇敢地追求梦想。而蓝羽和风灵之间的友谊也变得更加深厚，它们一起在天空中翱翔，享受着自由和快乐。<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(**tokenizer(\"给我讲一个故事吧\",return_tensors=\"pt\").to(\"cuda:1\"), max_new_tokens=500, do_sample=False)\n",
    "print(tokenizer.batch_decode(output)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,module in model.named_modules():\n",
    "    if name.endswith(\"self_attn\"):\n",
    "        # Orthogonal q_proj and k_up_proj\n",
    "        k_up_weight = deepcopy(module.k_up_proj.weight.data).reshape(n_heads, head_dim, latent_dim) # (n_heads, head_dim, latent_dim)\n",
    "        q_weight = deepcopy(module.q_proj.weight.data).reshape(n_heads, head_dim, hidden_size) # (n_heads, head_dim, hidden_size)\n",
    "        if module.q_proj.bias is not None:\n",
    "            q_weight = torch.cat([q_weight,deepcopy(module.q_proj.bias.data).reshape(n_heads, head_dim, 1)],dim=-1)\n",
    "        q_k_up = torch.einsum(\"hdc,hdD->hcD\",k_up_weight, q_weight) # (n_heads, latent_dim, hidden_size), rank<=head_dim\n",
    "        U,S,V = torch.svd_lowrank(q_k_up, head_dim, niter=16) # U(n_heads, latent_dim, head_dim), S(n_heads, head_dim), V(n_heads, hidden_size, head_dim)\n",
    "        US_sqrt = torch.einsum('hLd,hd->hdL',U,torch.sqrt(S)) # (n_heads, head_dim, latent_dim)\n",
    "        S_sqrtV = torch.einsum('hd,hDd->hdD',torch.sqrt(S),V) # (n_heads, head_dim, hidden_size)\n",
    "        if module.q_proj.bias is not None:\n",
    "            module.q_proj.bias.data = S_sqrtV[:,:,-1].reshape(-1).contiguous()\n",
    "            S_sqrtV = S_sqrtV[:,:,:-1]\n",
    "        module.k_up_proj.weight.data = US_sqrt.reshape(n_heads*head_dim, latent_dim).contiguous()\n",
    "        module.q_proj.weight.data = S_sqrtV.reshape(n_heads*head_dim, hidden_size).contiguous()\n",
    "\n",
    "        # Orthogonal o_proj and v_up_proj\n",
    "        v_up_weight = deepcopy(module.v_up_proj.weight.data).reshape(n_heads, head_dim, latent_dim)\n",
    "        o_weight = deepcopy(module.o_proj.weight.data).reshape(hidden_size, n_heads, head_dim)\n",
    "        v_up_o = torch.einsum(\"hdc,Dhd->hcD\",v_up_weight, o_weight) # (n_heads, latent_dim, hidden_size), rank<=head_dim\n",
    "        U,S,V = torch.svd_lowrank(v_up_o, head_dim, niter=16) # U(n_heads, latent_dim, head_dim), S(n_heads, head_dim), V(n_heads, hidden_size, head_dim)\n",
    "        US_sqrt = torch.einsum('hLd,hd->hdL',U,torch.sqrt(S)) # (n_heads, head_dim, latent_dim)\n",
    "        S_sqrtV = torch.einsum('hd,hDd->Dhd',torch.sqrt(S),V) # (hidden_size, n_heads, head_dim)\n",
    "        module.v_up_proj.weight.data = US_sqrt.reshape(hidden_size, latent_dim).contiguous()\n",
    "        module.o_proj.weight.data = S_sqrtV.reshape(hidden_size, n_heads*head_dim).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给我讲一个故事吧。\n",
      "当然可以，这是一个关于勇气和友谊的故事：\n",
      "\n",
      "从前，在一个遥远的森林里，住着一只名叫蓝羽的小鸟。蓝羽有着美丽的蓝色羽毛和甜美的歌声，但它有一个秘密——它害怕飞翔。每当其他鸟儿在天空中自由翱翔时，蓝羽总是躲在树枝上，不敢加入它们。\n",
      "\n",
      "一天，森林里的动物们决定举办一场飞行比赛，以庆祝春天的到来。所有的鸟儿都兴奋地准备着，只有蓝羽感到非常焦虑。它知道如果不去参加比赛，它将永远无法克服自己的恐惧。\n",
      "\n",
      "就在这时，一只名叫风灵的老鹰飞到了蓝羽的树上。风灵是森林中最勇敢的鸟儿之一，它看到了蓝羽的不安。风灵对蓝羽说：“蓝羽，我知道你害怕飞翔，但请相信我，只要你勇敢地迈出第一步，你就能够学会飞翔。”\n",
      "\n",
      "受到风灵的鼓励，蓝羽鼓起勇气，决定参加飞行比赛。在比赛的那天，所有的动物都聚集在森林中央，期待着看到精彩的表演。蓝羽站在起跑线上，心跳加速，但它没有退缩。\n",
      "\n",
      "随着一声哨响，所有的鸟儿都展翅高飞，只有蓝羽还在原地。就在这时，风灵飞到了蓝羽的身边，用翅膀轻轻推了它一下。蓝羽感到一股力量涌上心头，它闭上眼睛，深吸一口气，然后张开翅膀，飞向了天空。\n",
      "\n",
      "起初，蓝羽的飞行并不平稳，但它没有放弃。它努力地扇动翅膀，逐渐掌握了飞行的技巧。其他鸟儿看到了蓝羽的努力，纷纷为它加油鼓劲。最终，蓝羽成功地完成了比赛，赢得了所有人的掌声和尊重。\n",
      "\n",
      "从那以后，蓝羽不再害怕飞翔。它成为了森林中最勇敢的鸟儿之一，它的故事也激励着其他动物去面对自己的恐惧，勇敢地追求梦想。而蓝羽和风灵之间的友谊也变得更加深厚，它们一起在天空中翱翔，享受着自由和快乐。<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(**tokenizer(\"给我讲一个故事吧\",return_tensors=\"pt\").to(\"cuda:1\"), max_new_tokens=500, do_sample=False)\n",
    "print(tokenizer.batch_decode(output)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,module in model.named_modules():\n",
    "    if name.endswith(\"self_attn\"):\n",
    "        # Absorb k_up_proj into q_proj\n",
    "        k_up_weight = deepcopy(module.k_up_proj.weight.data).reshape(n_heads, head_dim, latent_dim) # (n_heads, head_dim, latent_dim)\n",
    "        q_weight = deepcopy(module.q_proj.weight.data).reshape(n_heads, head_dim, hidden_size) # (n_heads, head_dim, hidden_size)\n",
    "        if module.q_proj.bias is not None:\n",
    "            q_weight = torch.cat([q_weight,deepcopy(module.q_proj.bias.data).reshape(n_heads, head_dim, 1)],dim=-1)\n",
    "        q_k_up = torch.einsum(\"hdc,hdD->hcD\",k_up_weight, q_weight) # (n_heads, latent_dim, hidden_size), rank<=head_dim\n",
    "        q_proj = torch.nn.Linear(hidden_size, n_heads*latent_dim, bias=(module.q_proj.bias is not None))\n",
    "        q_proj = q_proj.to(device=module.q_proj.weight.device, dtype=module.q_proj.weight.dtype)\n",
    "        if module.q_proj.bias is not None:\n",
    "            q_proj.bias.data = q_k_up[:,:,-1].reshape(-1).contiguous()\n",
    "            q_k_up = q_k_up[:,:,:-1]\n",
    "        q_proj.weight.data = q_k_up.reshape(n_heads*latent_dim, hidden_size).contiguous()\n",
    "        setattr(module, \"q_proj\", q_proj)\n",
    "        delattr(module, \"k_up_proj\")\n",
    "        # Absorb v_up_proj into o_proj\n",
    "        v_up_weight = deepcopy(module.v_up_proj.weight.data).reshape(n_heads, head_dim, latent_dim) # (n_heads, head_dim, latent_dim)\n",
    "        o_weight = deepcopy(module.o_proj.weight.data).reshape(hidden_size, n_heads, head_dim) # (n_heads, head_dim, hidden_size)\n",
    "        v_up_o = torch.einsum(\"hdc,Dhd->Dhc\",v_up_weight, o_weight) # (hidden_size, n_heads, latent_dim), rank<=head_dim\n",
    "        o_proj = torch.nn.Linear(n_heads*latent_dim, hidden_size, bias=(module.o_proj.bias is not None))\n",
    "        o_proj = o_proj.to(device=module.o_proj.weight.device, dtype=module.o_proj.weight.dtype)\n",
    "        o_proj.weight.data = v_up_o.reshape(hidden_size, n_heads*latent_dim).contiguous()\n",
    "        if module.o_proj.bias is not None:\n",
    "            o_proj.bias.data = module.o_proj.bias\n",
    "        setattr(module, \"o_proj\", o_proj)\n",
    "        delattr(module, \"v_up_proj\")\n",
    "        module.absorb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给我讲一个故事吧。\n",
      "当然可以，这是一个关于勇气和友谊的故事：\n",
      "\n",
      "从前，在一个遥远的森林里，住着一只名叫蓝羽的小鸟。蓝羽有着美丽的蓝色羽毛和甜美的歌声，但它有一个秘密——它害怕飞翔。每当其他鸟儿在天空中自由翱翔时，蓝羽总是躲在树枝上，不敢加入它们。\n",
      "\n",
      "一天，森林里的动物们决定举办一场飞行比赛，以庆祝春天的到来。所有的鸟儿都兴奋地准备着，只有蓝羽感到非常焦虑。它知道如果不去参加比赛，它将永远无法克服自己的恐惧。\n",
      "\n",
      "就在这时，一只名叫风灵的老鹰飞到了蓝羽的树上。风灵是森林中最勇敢的鸟儿之一，它看到了蓝羽的不安。风灵对蓝羽说：“蓝羽，我知道你害怕飞翔，但请相信我，只要你勇敢地迈出第一步，你就能够学会飞翔。”\n",
      "\n",
      "受到风灵的鼓励，蓝羽鼓起勇气，决定参加飞行比赛。在比赛的那天，所有的动物都聚集在森林中央，期待着看到精彩的表演。蓝羽站在起跑线上，心跳加速，但它没有退缩。\n",
      "\n",
      "随着一声哨响，所有的鸟儿都展翅高飞，只有蓝羽还在原地。就在这时，风灵飞到了蓝羽的身边，用翅膀轻轻推了它一下。蓝羽感到一股力量涌上心头，它闭上眼睛，深吸一口气，然后张开翅膀，飞向了天空。\n",
      "\n",
      "起初，蓝羽的飞行并不平稳，但它没有放弃。它努力地扇动翅膀，逐渐掌握了飞行的技巧。其他鸟儿看到了蓝羽的努力，纷纷为它加油鼓劲。最终，蓝羽成功地完成了比赛，赢得了所有人的掌声和尊重。\n",
      "\n",
      "从那以后，蓝羽不再害怕飞翔。它成为了森林中最勇敢的鸟儿之一，它的故事也激励着其他动物去面对自己的恐惧，勇敢地追求梦想。而蓝羽和风灵之间的友谊也变得更加深厚，它们一起在天空中翱翔，享受着自由和快乐。<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(**tokenizer(\"给我讲一个故事吧\",return_tensors=\"pt\").to(\"cuda:1\"), max_new_tokens=500, do_sample=False)\n",
    "print(tokenizer.batch_decode(output)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transmla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
